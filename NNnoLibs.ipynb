{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwM0kOe4y7kmUxbq25JCWy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Syed-MuhammadTaha/NNnoLibs/blob/main/NNnoLibs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.special import expit as sigmoid"
      ],
      "metadata": {
        "id": "-iLVPMof8RNx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "class NeuralNetwork:\n",
        "    # The NN constructor initializes the 2-layer NN with 4 neurons in layer 1 and a sigmoid output neuron\n",
        "    \"\"\"\n",
        "    Dimensions (conventions established from Andrew Ng's lectures) :\n",
        "      X.T : (n_x, m)\n",
        "      weights1: (4, n_x)  4 neurons + n_x weights\n",
        "      a[1]: (4, m)  Since W1.X\n",
        "      weights2: (1, 4)\n",
        "      final output: (1, m) since W2.a[1]\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.input = X.T\n",
        "        self.weights1 = np.random.rand(4, self.input.shape[0])\n",
        "        self.weights2 = np.random.rand(1, 4)\n",
        "        self.y = y\n",
        "        self.output = np.zeros(y.shape)\n",
        "\n",
        "    def feedforward(self):\n",
        "        self.layer1 = sigmoid(np.dot(self.weights1, self.input))\n",
        "        self.output = sigmoid(np.dot(self.weights2, self.layer1))\n",
        "        return self.output\n",
        "    # Lost a lot of time in getting the backprop dimensions right :(\n",
        "    def backprop(self):\n",
        "        d_weights2 = np.dot( (2*(self.y - self.output) * sigmoid_derivative(self.output)), self.layer1.T)\n",
        "        d_weights1 = np.dot( (np.dot(self.weights2.T,2*(self.y - self.output) * sigmoid_derivative(self.output))) * sigmoid_derivative(self.layer1), self.input.T)\n",
        "\n",
        "\n",
        "        self.weights1 += d_weights1\n",
        "        self.weights2 += d_weights2\n",
        "\n",
        "    def train(self, X, y):\n",
        "        self.output = self.feedforward()\n",
        "        self.backprop()"
      ],
      "metadata": {
        "id": "oba4Y5XR5ccx"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array(([0,0,1],[0,1,1],[1,0,1],[1,1,1],[0,1,0]), dtype=float)\n",
        "y=np.array(([0, 1, 1,0,1]), dtype=float)"
      ],
      "metadata": {
        "id": "RPjOvcA8G-Lq"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoneuyOM4MOl",
        "outputId": "aa16210c-100d-4d4d-df73-4b167def813c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for iteration # 0\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]\n",
            " [0. 1. 0.]]\n",
            "Actual Output: \n",
            "[0. 1. 1. 0. 1.]\n",
            "Predicted Output: \n",
            "[[0.78793433 0.82579244 0.84338404 0.86603773 0.80179301]]\n",
            "Loss: \n",
            "0.29300494053461434\n",
            "\n",
            "\n",
            "for iteration # 100\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]\n",
            " [0. 1. 0.]]\n",
            "Actual Output: \n",
            "[0. 1. 1. 0. 1.]\n",
            "Predicted Output: \n",
            "[[0.18007087 0.78838304 0.49761986 0.54571893 0.92336074]]\n",
            "Loss: \n",
            "0.12665515913356395\n",
            "\n",
            "\n",
            "for iteration # 200\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]\n",
            " [0. 1. 0.]]\n",
            "Actual Output: \n",
            "[0. 1. 1. 0. 1.]\n",
            "Predicted Output: \n",
            "[[0.07190205 0.87215142 0.80250018 0.23117691 0.88534136]]\n",
            "Loss: \n",
            "0.0254221422716776\n",
            "\n",
            "\n",
            "for iteration # 300\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]\n",
            " [0. 1. 0.]]\n",
            "Actual Output: \n",
            "[0. 1. 1. 0. 1.]\n",
            "Predicted Output: \n",
            "[[0.03840923 0.92392553 0.89065707 0.12937673 0.92787751]]\n",
            "Loss: \n",
            "0.008231692510305111\n",
            "\n",
            "\n",
            "for iteration # 400\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]\n",
            " [0. 1. 0.]]\n",
            "Actual Output: \n",
            "[0. 1. 1. 0. 1.]\n",
            "Predicted Output: \n",
            "[[0.02755164 0.94268217 0.91930645 0.0956774  0.94508092]]\n",
            "Loss: \n",
            "0.004545229327882575\n",
            "\n",
            "\n",
            "for iteration # 500\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]\n",
            " [0. 1. 0.]]\n",
            "Actual Output: \n",
            "[0. 1. 1. 0. 1.]\n",
            "Predicted Output: \n",
            "[[0.02209227 0.95256081 0.93390904 0.07845486 0.95430858]]\n",
            "Loss: \n",
            "0.003069886359699928\n",
            "\n",
            "\n",
            "for iteration # 600\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]\n",
            " [0. 1. 0.]]\n",
            "Actual Output: \n",
            "[0. 1. 1. 0. 1.]\n",
            "Predicted Output: \n",
            "[[0.01874484 0.95880146 0.94297383 0.06775138 0.96017891]]\n",
            "Loss: \n",
            "0.002295328336440023\n",
            "\n",
            "\n",
            "for iteration # 700\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]\n",
            " [0. 1. 0.]]\n",
            "Actual Output: \n",
            "[0. 1. 1. 0. 1.]\n",
            "Predicted Output: \n",
            "[[0.01645264 0.96317064 0.94924838 0.06033702 0.96430391]]\n",
            "Loss: \n",
            "0.0018235170300214584\n",
            "\n",
            "\n",
            "for iteration # 800\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]\n",
            " [0. 1. 0.]]\n",
            "Actual Output: \n",
            "[0. 1. 1. 0. 1.]\n",
            "Predicted Output: \n",
            "[[0.01476896 0.96643709 0.95390107 0.05483602 0.96739488]]\n",
            "Loss: \n",
            "0.0015079571724751942\n",
            "\n",
            "\n",
            "for iteration # 900\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]\n",
            " [0. 1. 0.]]\n",
            "Actual Output: \n",
            "[0. 1. 1. 0. 1.]\n",
            "Predicted Output: \n",
            "[[0.01347092 0.96899266 0.95751845 0.05055706 0.96981704]]\n",
            "Loss: \n",
            "0.001282926011618565\n",
            "\n",
            "\n",
            "for iteration # 1000\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]\n",
            " [0. 1. 0.]]\n",
            "Actual Output: \n",
            "[0. 1. 1. 0. 1.]\n",
            "Predicted Output: \n",
            "[[0.01243412 0.97105971 0.96042976 0.04711189 0.97177858]]\n",
            "Loss: \n",
            "0.0011147859300421944\n",
            "\n",
            "\n",
            "for iteration # 1100\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]\n",
            " [0. 1. 0.]]\n",
            "Actual Output: \n",
            "[0. 1. 1. 0. 1.]\n",
            "Predicted Output: \n",
            "[[0.01158333 0.97277464 0.96283524 0.04426427 0.97340759]]\n",
            "Loss: \n",
            "0.0009846190141602422\n",
            "\n",
            "\n",
            "for iteration # 1200\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]\n",
            " [0. 1. 0.]]\n",
            "Actual Output: \n",
            "[0. 1. 1. 0. 1.]\n",
            "Predicted Output: \n",
            "[[0.0108702  0.9742262  0.96486428 0.04186149 0.97478757]]\n",
            "Loss: \n",
            "0.0008810040604420628\n",
            "\n",
            "\n",
            "for iteration # 1300\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]\n",
            " [0. 1. 0.]]\n",
            "Actual Output: \n",
            "[0. 1. 1. 0. 1.]\n",
            "Predicted Output: \n",
            "[[0.01026209 0.97547487 0.96660455 0.03980005 0.97597552]]\n",
            "Loss: \n",
            "0.0007966536936279886\n",
            "\n",
            "\n",
            "for iteration # 1400\n",
            "\n",
            "Input : \n",
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 1.]\n",
            " [0. 1. 0.]]\n",
            "Actual Output: \n",
            "[0. 1. 1. 0. 1.]\n",
            "Predicted Output: \n",
            "[[0.00973617 0.97656343 0.96811777 0.03800707 0.97701182]]\n",
            "Loss: \n",
            "0.0007267071774727343\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "NN = NeuralNetwork(X,y)\n",
        "for i in range(1500): # trains the NN 1,000 times\n",
        "    if i % 100 ==0:\n",
        "        print (\"for iteration # \" + str(i) + \"\\n\")\n",
        "        print (\"Input : \\n\" + str(X))\n",
        "        print (\"Actual Output: \\n\" + str(y))\n",
        "        print (\"Predicted Output: \\n\" + str(NN.feedforward()))\n",
        "        print (\"Loss: \\n\" + str(np.mean(np.square(y - NN.feedforward())))) # mean sum squared loss\n",
        "        print (\"\\n\")\n",
        "    NN.train(X, y)"
      ]
    }
  ]
}